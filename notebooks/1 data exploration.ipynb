{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `pip` to install some libraries that we are going to use\n",
    "\n",
    "* pandas: Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.\n",
    "* seaborn: Seaborn is a Python data visualization library based on matplotlib.\n",
    "* matplotlib: Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. \n",
    "* numpy: Numpy is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays.\n",
    "* dvc: Data Version Control for your machine learning projects. \n",
    "* s3fs: 3FS builds on botocore to provide a convenient Python filesystem interface for S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../src/train/requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart the Jupyter kernel after installing pip packages.\n",
    "\n",
    "Let's import pandas using the alias `pd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the CSV from a S3 bucket.\n",
    "\n",
    "The [datasets](https://www.kaggle.com/mlg-ulb/creditcardfraud) contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. \n",
    "\n",
    "* Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset.\n",
    "* The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
    "* Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dvc.api\n",
    "import s3fs\n",
    "import os\n",
    "\n",
    "# The credidcard.csv versioning metadata is kept in a git repository in os.environ['DATA_REPO'].\n",
    "# We are pulling version 1.0 of the data and the data itself is from a S3 bucket that is returned\n",
    "# by dvc.api.get_url()\n",
    "resource_url = dvc.api.get_url(\n",
    "    path='creditcard.csv',\n",
    "    repo=os.environ['DATA_REPO'],\n",
    "    rev='v1.0')\n",
    "\n",
    "print(\"Data is from this S3 bucket:\\n{}\".format(resource_url))\n",
    "\n",
    "# Pandas doens't support endpoint_url\n",
    "# https://github.com/pandas-dev/pandas/pull/29050\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': os.environ['S3_ENDPOINT_URL']})\n",
    "df = pd.read_csv(fs.open(resource_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data types. Feature 'Class' is the response variable and it takes a value of 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descritive stats \n",
    "df.describe().round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null and missing values\n",
    "data = df.fillna(np.nan)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount'].describe().round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = df[df['Class']==1]\n",
    "normal = df[df['Class']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 492 fraud and 284315 normal transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the precentage of fraud vs normal\n",
    "print('Normal', round(fraud.shape[0]/len(df) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(normal.shape[0]/len(df) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal.Amount.describe().round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud.Amount.describe().round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the average fraud value?\n",
    "print('Average Fraud: {} | Average Normal: {}'.format(normal['Amount'].mean() , fraud['Amount'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the highest fraud value?\n",
    "print('Max Fraud: {} | Max Normal: {}'.format(normal['Amount'].max() , fraud['Amount'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('Class', data=df)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "sns.distplot(fraud.Amount, bins=50, kde=False, ax=ax1, axlabel=False)\n",
    "sns.distplot(normal.Amount, bins=50, kde=False, ax=ax2, axlabel=False)\n",
    "\n",
    "f.suptitle('Transaction by Class')\n",
    "\n",
    "ax1.set_title('Fraud')\n",
    "ax2.set_title('Normal')\n",
    "plt.xlabel('Amount ($)')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pearson correlation\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.title('Correlation matrix', fontsize=16)\n",
    "sns.heatmap(df.corr(method='pearson'), annot=True, fmt=\".2f\", cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Class' is less correlated with ‘Amount’ and ‘Time’ which suggests it is hard to predict whether transaction is fraudulent or not from ‘Amount’ and ‘Time’ details of transaction.\n",
    "\n",
    "'Class' is negatively correlated with ‘V3’, ‘V7’, ‘V10’, ‘V12’, ‘V14’, ‘V17’ and positively correlated with ‘V2’, ‘V4’, ‘V11’. The other correlations are relatively small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}